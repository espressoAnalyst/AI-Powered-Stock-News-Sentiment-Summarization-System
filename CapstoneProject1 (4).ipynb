{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1><center><font size=10>Introduction to LLMs and GenAI</center></font></h1>\n",
        "<h1><center>Capstone Project 1 : AI-Powered Stock News Sentiment & Summarization System</center></h1>"
      ],
      "metadata": {
        "id": "6PSLxwemy8dU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Context"
      ],
      "metadata": {
        "id": "AGn8bZsdzAHn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stock prices are influenced by company performance, innovations, collaborations, and market sentiment. Rapidly emerging news and media reports can significantly sway investor perceptions, making it challenging for analysts to keep up with the volume of information. Investment firms need AI tools to quickly assess market sentiment and integrate insights into trading strategies."
      ],
      "metadata": {
        "id": "qwTp2kMHzA8h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objective"
      ],
      "metadata": {
        "id": "YnpPuebGzDAO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To develop an AI system that:\n",
        "\n",
        "- Analyzes historical financial news to determine market sentiment toward a NASDAQ-listed company.\n",
        "\n",
        "- Generates weekly sentiment summaries of the news.\n",
        "\n",
        "- Correlates sentiment trends with stock price movements (Open, High, Low, Close, Volume).\n",
        "\n",
        "- Provides analysts with actionable insights for trading and investment decisions."
      ],
      "metadata": {
        "id": "4SGcxrdbzFdk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Dictionary"
      ],
      "metadata": {
        "id": "4u9vSVpLzHUn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Date: The date the news was released\n",
        "\n",
        "- News: The content of news articles that could potentially affect the company's stock price\n",
        "\n",
        "- Open: The stock price (in $) at the beginning of the day\n",
        "\n",
        "- High: The highest stock price (in $) reached during the day\n",
        "\n",
        "- Low: The lowest stock price (in $) reached during the day\n",
        "\n",
        "- Close: The adjusted stock price (in $) at the end of the day\n",
        "\n",
        "- Volume: The number of shares traded during the day\n",
        "\n",
        "- Label: The sentiment polarity of the news content\n",
        "\t -  1: Positive\n",
        "\t -  0: Neutral\n",
        "\t -  -1: Negative\n"
      ],
      "metadata": {
        "id": "HOU0KJC6zJmc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup & Install Libraries"
      ],
      "metadata": {
        "id": "BnlvK9dXzQsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install pandas numpy matplotlib seaborn plotly\n",
        "!pip install sentence-transformers\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install scikit-learn\n",
        "!pip install tqdm"
      ],
      "metadata": {
        "id": "T6ycvIGJzTSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from tqdm import tqdm\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "A7-1WdoazhaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load & Inspect Data"
      ],
      "metadata": {
        "id": "LR9aQjm8zleO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your dataset (CSV with Date, News, Open, High, Low, Close, Volume, Label)\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Intro to LLM and Gen AI/stock_news.csv\")\n",
        "\n",
        "# Inspect the first few rows\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "MGpn_dbKznCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check data info\n",
        "df.info()\n",
        "\n",
        "# Check missing values\n",
        "df.isnull().sum()\n",
        "\n",
        "# Parse date column to datetime\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n"
      ],
      "metadata": {
        "id": "G7XSr4ot_i-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Text Preprocessing"
      ],
      "metadata": {
        "id": "P3S5yIHy_mBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'http\\S+', '', text)          # remove URLs\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # remove punctuation\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()    # remove extra spaces\n",
        "    return text\n",
        "\n",
        "# Apply preprocessing\n",
        "df['clean_news'] = df['News'].apply(clean_text)\n",
        "\n",
        "# Preview\n",
        "df[['News', 'clean_news']].head()\n"
      ],
      "metadata": {
        "id": "ljNQqQab_nZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generate Embeddings for News"
      ],
      "metadata": {
        "id": "z1u3vAe-_rqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained Sentence Transformer\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Generate embeddings\n",
        "news_embeddings = model.encode(df['clean_news'].tolist(), batch_size=32, show_progress_bar=True)\n",
        "\n",
        "# Convert embeddings to numpy array\n",
        "news_embeddings = np.array(news_embeddings)\n",
        "print(\"Embeddings shape:\", news_embeddings.shape)\n"
      ],
      "metadata": {
        "id": "Bluy8lzg_tDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Sentiment Analysis Using Labels / LLM"
      ],
      "metadata": {
        "id": "6Ze5ObDt_y5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check distribution\n",
        "sns.countplot(x='Label', data=df)\n",
        "plt.title(\"Sentiment Distribution\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ZoEfxpr4_0TQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Weekly Sentiment Aggregation"
      ],
      "metadata": {
        "id": "nKQ0ShQb_6s0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a week column\n",
        "df['Week'] = df['Date'].dt.to_period('W').apply(lambda r: r.start_time)\n",
        "\n",
        "# Aggregate weekly sentiment\n",
        "weekly_sentiment = df.groupby('Week')['Label'].mean().reset_index()\n",
        "weekly_sentiment.head()\n",
        "\n",
        "# Plot weekly sentiment\n",
        "plt.figure(figsize=(12,5))\n",
        "sns.lineplot(x='Week', y='Label', data=weekly_sentiment)\n",
        "plt.title(\"Weekly Average Sentiment\")\n",
        "plt.xlabel(\"Week\")\n",
        "plt.ylabel(\"Average Sentiment\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YfNlohFc_73l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Weekly Stock Summary"
      ],
      "metadata": {
        "id": "zQYj0sQQABWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aggregate weekly stock data\n",
        "weekly_stock = df.groupby('Week').agg({\n",
        "    'Open': 'first',\n",
        "    'High': 'max',\n",
        "    'Low': 'min',\n",
        "    'Close': 'last',\n",
        "    'Volume': 'sum'\n",
        "}).reset_index()\n",
        "\n",
        "# Merge sentiment and stock\n",
        "weekly_data = weekly_stock.merge(weekly_sentiment, on='Week')\n",
        "weekly_data.head()\n"
      ],
      "metadata": {
        "id": "BZzQpSBWACWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Correlation Analysis"
      ],
      "metadata": {
        "id": "NzVRwlWMAGRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute correlation between sentiment and stock movement\n",
        "weekly_data['Pct_Change'] = (weekly_data['Close'] - weekly_data['Open']) / weekly_data['Open'] * 100\n",
        "\n",
        "# Plot correlation\n",
        "sns.scatterplot(x='Label', y='Pct_Change', data=weekly_data)\n",
        "plt.title(\"Weekly Sentiment vs Stock % Change\")\n",
        "plt.show()\n",
        "\n",
        "# Correlation coefficient\n",
        "corr = weekly_data['Label'].corr(weekly_data['Pct_Change'])\n",
        "print(f\"Correlation between sentiment and stock % change: {corr:.2f}\")\n"
      ],
      "metadata": {
        "id": "IANncS5LAIBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Weekly News Summarization (LLM)"
      ],
      "metadata": {
        "id": "WEYNzzlIAMN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load summarization pipeline\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "# Example: summarize all news in a week\n",
        "def summarize_weekly_news(week):\n",
        "    texts = df[df['Week'] == week]['clean_news'].tolist()\n",
        "    if len(texts) == 0:\n",
        "        return \"\"\n",
        "    combined_text = \" \".join(texts)[:2000]  # limit to 2000 chars for model\n",
        "    summary = summarizer(combined_text, max_length=100, min_length=40, do_sample=False)\n",
        "    return summary[0]['summary_text']\n",
        "\n",
        "# Add summary column\n",
        "weekly_data['Weekly_Summary'] = weekly_data['Week'].apply(summarize_weekly_news)\n",
        "weekly_data[['Week','Weekly_Summary']].head()\n"
      ],
      "metadata": {
        "id": "ZDqjpII_ANMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generate Automated Actionable Insights"
      ],
      "metadata": {
        "id": "6t3wkOh5AkiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to generate insights\n",
        "def generate_insights(row):\n",
        "    insights = []\n",
        "\n",
        "    # Positive sentiment followed by price rise\n",
        "    if row['Label'] > 0 and row['Pct_Change'] > 0:\n",
        "        insights.append(f\"Positive news sentiment ({row['Label']:.2f}) preceded a price increase of {row['Pct_Change']:.2f}%\")\n",
        "\n",
        "    # Negative sentiment followed by price drop\n",
        "    if row['Label'] < 0 and row['Pct_Change'] < 0:\n",
        "        insights.append(f\"Negative news sentiment ({row['Label']:.2f}) preceded a price decrease of {row['Pct_Change']:.2f}%\")\n",
        "\n",
        "    # Neutral sentiment\n",
        "    if row['Label'] == 0:\n",
        "        insights.append(\"Neutral sentiment observed this week; minimal price impact\")\n",
        "\n",
        "    # Large price change with low sentiment\n",
        "    if abs(row['Pct_Change']) > 5 and abs(row['Label']) < 0.3:\n",
        "        insights.append(f\"Stock moved {row['Pct_Change']:.2f}% despite neutral sentiment; investigate external factors\")\n",
        "\n",
        "    return insights\n",
        "\n",
        "# Apply to weekly data\n",
        "weekly_data['Insights'] = weekly_data.apply(generate_insights, axis=1)\n",
        "weekly_data[['Week', 'Label', 'Pct_Change', 'Insights']].head(10)\n"
      ],
      "metadata": {
        "id": "_tSRRFscAlmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Interactive Visualizations with Plotly"
      ],
      "metadata": {
        "id": "Fz7hU4qzAqz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Weekly Sentiment vs Stock Price\n",
        "import plotly.express as px\n",
        "\n",
        "fig = px.line(\n",
        "    weekly_data, x='Week', y=['Label', 'Close'],\n",
        "    title=\"Weekly Sentiment vs Stock Close Price\",\n",
        "    labels={'value':'Score / Price', 'Week':'Week'},\n",
        ")\n",
        "fig.update_layout(yaxis_title=\"Sentiment / Close Price\")\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "MuE679l0Arz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Scatter Plot: Sentiment vs % Change\n",
        "fig = px.scatter(\n",
        "    weekly_data, x='Label', y='Pct_Change',\n",
        "    text='Week', size='Volume',\n",
        "    color='Label', color_continuous_scale='RdYlGn',\n",
        "    title=\"Weekly Sentiment vs Stock % Change\",\n",
        "    labels={'Label':'Avg Sentiment', 'Pct_Change':'Stock % Change'}\n",
        ")\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "AGmJe4vcA1-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Weekly News Summary Dashboard\n",
        "for idx, row in weekly_data.iterrows():\n",
        "    print(f\"Week: {row['Week'].date()}\")\n",
        "    print(f\"Avg Sentiment: {row['Label']:.2f} | % Change: {row['Pct_Change']:.2f}%\")\n",
        "    print(f\"Weekly Summary: {row['Weekly_Summary']}\")\n",
        "    if row['Insights']:\n",
        "        print(\"Insights:\")\n",
        "        for insight in row['Insights']:\n",
        "            print(f\"- {insight}\")\n",
        "    print(\"-\"*80)\n"
      ],
      "metadata": {
        "id": "WwPpF9GTA2zV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LLM-Powered Analyst Recommendations"
      ],
      "metadata": {
        "id": "nY4cVUsSBR4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries (if not already installed)\n",
        "!pip install transformers torch sentence-transformers tqdm\n",
        "\n",
        "# Import libraries\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Make sure GPU is used\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "print(\"Using device:\", \"GPU\" if device == 0 else \"CPU\")\n"
      ],
      "metadata": {
        "id": "Cl4X2-UCBS2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load the GPT-Neo Model"
      ],
      "metadata": {
        "id": "ezWq7vjdDDFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load EleutherAI GPT-Neo 2.7B text-generation pipeline\n",
        "llm = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=\"EleutherAI/gpt-neo-2.7B\",\n",
        "    device=device,\n",
        "    tokenizer=\"EleutherAI/gpt-neo-2.7B\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "RdUv-Xm7B-pf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define LLM Insight Generation Function\n",
        "def llm_generate_insights(row):\n",
        "    \"\"\"\n",
        "    Generates actionable analyst insights using GPT-Neo 2.7B\n",
        "    Input: row from weekly_data containing 'Weekly_Summary', 'Label', 'Pct_Change'\n",
        "    Output: List of actionable insights\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are a financial analyst.\n",
        "    Based on the following information, generate 2-3 concise, actionable insights for investors.\n",
        "\n",
        "    Weekly Summary: {row['Weekly_Summary']}\n",
        "    Average Sentiment Score: {row['Label']:.2f}  (1=Positive, 0=Neutral, -1=Negative)\n",
        "    Stock % Change: {row['Pct_Change']:.2f}%\n",
        "\n",
        "    Provide insights in bullet points.\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate text using the model\n",
        "    output = llm(prompt, max_length=200, do_sample=True, temperature=0.7)\n",
        "\n",
        "    # Extract generated text\n",
        "    generated_text = output[0]['generated_text']\n",
        "\n",
        "    # Optional: clean the text by splitting into bullet points\n",
        "    insights = [line.strip(\"-â€¢ \\n\") for line in generated_text.split(\"\\n\") if len(line.strip())>0]\n",
        "\n",
        "    return insights\n"
      ],
      "metadata": {
        "id": "PgT3yPUtC7vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Make sure the column exists first\n",
        "weekly_data['LLM_Insights'] = None\n",
        "\n",
        "# Apply LLM generation for first 5 weeks (demo)\n",
        "for idx, row in tqdm(weekly_data.head(5).iterrows(), total=5):\n",
        "    weekly_data.at[idx, 'LLM_Insights'] = llm_generate_insights(row)\n",
        "\n",
        "# Preview results\n",
        "weekly_data[['Week', 'Weekly_Summary', 'Label', 'Pct_Change', 'LLM_Insights']].head()\n"
      ],
      "metadata": {
        "id": "LZpHhDZsDIbl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display LLM-Powered Insights Nicely\n",
        "for idx, row in weekly_data.head(5).iterrows():\n",
        "    print(f\"Week: {row['Week'].date()}\")\n",
        "    print(f\"Average Sentiment: {row['Label']:.2f} | % Change: {row['Pct_Change']:.2f}%\")\n",
        "    print(f\"Weekly Summary: {row['Weekly_Summary']}\")\n",
        "    if row['LLM_Insights']:\n",
        "        print(\"LLM Insights:\")\n",
        "        for insight in row['LLM_Insights']:\n",
        "            print(f\"- {insight}\")\n",
        "    print(\"-\"*80)\n"
      ],
      "metadata": {
        "id": "mTH7c6u3DNv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Interactive Filters with Plotly & Widgets"
      ],
      "metadata": {
        "id": "46apFUOQECae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipywidgets\n",
        "from ipywidgets import widgets\n",
        "from IPython.display import display\n",
        "\n",
        "# Date range slider\n",
        "start_date = weekly_data['Week'].min()\n",
        "end_date = weekly_data['Week'].max()\n",
        "\n",
        "date_range = widgets.SelectionRangeSlider(\n",
        "    options=weekly_data['Week'],\n",
        "    index=(0, len(weekly_data)-1),\n",
        "    description='Select Weeks',\n",
        "    orientation='horizontal',\n",
        "    layout={'width':'800px'}\n",
        ")\n",
        "\n",
        "display(date_range)\n",
        "\n",
        "# Function to update chart\n",
        "def update_chart(change):\n",
        "    selected_weeks = change['new']\n",
        "    filtered_data = weekly_data[(weekly_data['Week'] >= selected_weeks[0]) &\n",
        "                                (weekly_data['Week'] <= selected_weeks[1])]\n",
        "\n",
        "    fig = px.line(filtered_data, x='Week', y=['Label','Close'],\n",
        "                  title=\"Weekly Sentiment vs Stock Close Price\")\n",
        "    fig.show()\n",
        "\n",
        "date_range.observe(update_chart, names='value')\n"
      ],
      "metadata": {
        "id": "qaDn8fr6ED7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Export Reports (CSV/PDF)"
      ],
      "metadata": {
        "id": "EWHJKkN9EK3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save weekly data with insights\n",
        "weekly_data.to_csv(\"weekly_stock_insights.csv\", index=False)\n",
        "print(\"CSV report saved!\")\n"
      ],
      "metadata": {
        "id": "cgrUdSdgEL90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fpdf\n",
        "from fpdf import FPDF\n",
        "\n",
        "pdf = FPDF()\n",
        "pdf.set_auto_page_break(auto=True, margin=15)\n",
        "pdf.add_page()\n",
        "pdf.set_font(\"Arial\", size=12)\n",
        "\n",
        "for idx, row in weekly_data.iterrows():\n",
        "    pdf.multi_cell(0, 8, f\"Week: {row['Week'].date()}\")\n",
        "    pdf.multi_cell(0, 8, f\"Avg Sentiment: {row['Label']:.2f} | % Change: {row['Pct_Change']:.2f}%\")\n",
        "    pdf.multi_cell(0, 8, f\"Weekly Summary: {row['Weekly_Summary']}\")\n",
        "\n",
        "    # Handle LLM_Insights as a list\n",
        "    if 'LLM_Insights' in row and row['LLM_Insights']:\n",
        "        pdf.multi_cell(0, 8, \"LLM Insights:\")\n",
        "        # Join list into a single string with newlines\n",
        "        insights_text = \"\\n\".join(row['LLM_Insights'])\n",
        "        pdf.multi_cell(0, 8, insights_text)\n",
        "\n",
        "    pdf.multi_cell(0, 8, \"-\"*80)\n",
        "\n",
        "pdf.output(\"Weekly_Stock_Insights.pdf\")\n",
        "print(\"PDF report saved!\")\n"
      ],
      "metadata": {
        "id": "-ncQk20LEOk1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}